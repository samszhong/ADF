# Azure Data Factory Repository

This repository is prepared for integrating an Azure Data Factory (ADF) instance with Git (GitHub).

## Overview
This repo will store the JSON definitions of your ADF assets (pipelines, datasets, linked services, triggers, integration runtimes, data flows, notebooks) once you connect the Data Factory portal to Git. Initially it is an empty scaffold so you can immediately configure Git integration.

## Folder Structure
```
factory/                Data Factory root metadata file (<factoryName>.json) will appear here after connect.
linkedService/          Linked service JSON definitions.
dataset/                Dataset JSON definitions.
pipeline/               Pipeline JSON definitions.
trigger/                Trigger JSON definitions.
integrationRuntime/     Self-hosted or managed IR definitions.
dataflow/               Mapping/wrangling data flows (if used).
notebook/               Notebooks (if using Synapse-style integration).
```
(Each folder contains a placeholder `.gitkeep` so Git tracks the directory.)

## Connecting Azure Data Factory to this Repo
1. Open the Azure portal and navigate to your Data Factory: `YOUR_DATA_FACTORY_NAME` (replace later).
2. In the ADF UI, select **Manage (wrench icon)** > **Source control** > **Git configuration**.
3. Choose:
   - Repository type: GitHub
   - Authentication: (Authorize your GitHub account if prompted)
   - GitHub repository: `samszhong/ADF`
   - Collaboration branch: `main`
   - Publish branch: `adf_publish` (ADF will create this on first Publish)
   - Root folder: `/` (unless you want a subfolder)
   - Import existing resources: Choose as appropriate:
     - If a Data Factory already has live (ARM) resources you want to bring under source control: **Import**.
     - If it is new/empty: **Do not import**.
4. Save. Your first Save of a pipeline/dataset/etc. will generate JSON files under these folders.

## Branching Model
- `main`: Collaboration branch (day-to-day JSON editing in ADF UI). You can add feature branches later if you wish.
- `adf_publish`: Auto-generated by ADF when you click **Publish**. It contains ARM templates (and associated files) used for deployment.

Important: Do **not** manually edit or delete files in `adf_publish`; treat it as an output branch.

## Typical Workflow
1. Edit / create pipelines, datasets, etc. in ADF UI (connected to `main`).
2. Click **Save** frequently (commits to `main`).
3. When ready to release to higher environments, click **Publish**.
4. Deployment tooling (e.g., Azure DevOps or GitHub Actions) can consume the ARM template artifacts from `adf_publish`.

## Adding a Feature Branch (Optional)
You can introduce a branching strategy later:
- Create a branch (e.g., `feature/my-new-pipeline`) before you start changes.
- In ADF Git configuration, switch to that branch to work in isolation.
- Merge via Pull Request back into `main`.

## CI/CD (Future Placeholder)
A GitHub Actions workflow can be added later to:
- Validate ARM templates after `adf_publish` updates.
- Deploy to test/stage/production using `az deployment` or Bicep/Terraform wrappers.

## Notes & Recommendations
- Keep secrets out of linked service JSON by using Key Vault references.
- Avoid committing large binary artifacts; store only JSON metadata and notebook source.
- Consider adding a LICENSE, CONTRIBUTING.md, and SECURITY.md if this becomes collaborative.

## Next Steps
1. Complete Git integration in the ADF portal.
2. Create or import your first pipeline and Save.
3. (Optional) Add deployment automation.
4. Add a license if this will be publicly reused.

---
Generated scaffold on initialization.
